{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.0"
    },
    "colab": {
      "name": "ch06.ipynb",
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/smabb/p/blob/main/Data_loading.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": true,
        "editable": true,
        "id": "8UW18_nPYfbY"
      },
      "source": [
        "# Data Loading, Storage, "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "io1-mCgsYkS-"
      },
      "source": [
        "Accessing data is a necessary first step . I’m\n",
        "going to be focused on data input and output using pandas, though there are numerous\n",
        "tools in other libraries to help with reading and writing data in various formats.\n",
        "Input and output typically falls into a few main categories: reading text files and other\n",
        "more efficient on-disk formats, loading data from databases, and interacting with network\n",
        "sources like web APIs."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": true,
        "editable": true,
        "id": "xwDr33VQYfbk"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": true,
        "editable": true,
        "id": "YeK4V0YVYfb6"
      },
      "source": [
        "## Reading and Writing Data in Text Format"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kaTOR5o2Y9S9"
      },
      "source": [
        "Pandas features a number of functions for reading tabular data as a DataFrame\n",
        "object. Table 6-1 summarizes some of them."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wrgcSPfjZGqU"
      },
      "source": [
        "* `read_csv`                 Load delimited data from a file, URL, or file-like object; use comma as default delimiter\n",
        "\n",
        "* `read_table` Load delimited data from a file, URL, or file-like object; use tab ('\\t') as default delimiter\n",
        "\n",
        "* `read_fwf` Read data in fixed-width column format (i.e., no delimiters)\n",
        "\n",
        "* `read_clipboard` Version of read_table that reads data from the clipboard; useful for converting tables from web\n",
        "pages\n",
        "\n",
        "* `read_excel` Read tabular data from an Excel XLS or XLSX file\n",
        "\n",
        "* `read_hdf` Read HDF5 files written by pandas\n",
        "\n",
        "* `read_html` Read all tables found in the given HTML document\n",
        "\n",
        "* `read_json` Read data from a JSON (JavaScript Object Notation) string \n",
        "representation\n",
        "\n",
        "* `read_msgpack` Read pandas data encoded using the MessagePack binary format\n",
        "\n",
        "* `read_pickle` Read an arbitrary object stored in Python pickle format\n",
        "* `read_sas` Read a SAS dataset stored in one of the SAS system’s custom storage formats\n",
        "\n",
        "* `read_sql` Read the results of a SQL query (using SQLAlchemy) as a pandas DataFrame\n",
        "\n",
        "* `read_stata` Read a dataset from Stata file format\n",
        "\n",
        "* `read_feather` Read the Feather binary file format"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-wZ8GfSkbWaW"
      },
      "source": [
        "Handling dates and other custom types can require extra effort. Let’s start with a\n",
        "small comma-separated (CSV) text file:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": true,
        "editable": true,
        "id": "87Z6mT3HYfb-",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "ed0a88d3-48d8-4bda-caad-38ed67358d8b"
      },
      "source": [
        "%cd examples"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/examples\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E1HxkGoFbveb"
      },
      "source": [
        "Since this is comma-delimited, we can use read_csv to read it into a DataFrame:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": true,
        "editable": true,
        "id": "yBPoNXv6YfcK"
      },
      "source": [
        "df = pd.read_csv('ex1.csv')\n",
        "df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qR35kOjnby6Y"
      },
      "source": [
        "We could also have used read_table and specified the delimiter:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": true,
        "editable": true,
        "id": "VYiCjKE_YfcW"
      },
      "source": [
        "pd.read_table('ex1.csv', sep=',')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GGIZAbX3b7Wb"
      },
      "source": [
        "A file will not always have a header row. Consider this file:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": true,
        "editable": true,
        "id": "mDJo5qQWYfcf"
      },
      "source": [
        "!cat ex2.csv"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NBBnFHXOcNjY"
      },
      "source": [
        "To read this file, you have a couple of options. You can allow pandas to assign default\n",
        "column names, or you can specify names yourself:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": true,
        "editable": true,
        "id": "Kbtvg9X7Yfcq"
      },
      "source": [
        "pd.read_csv('ex2.csv', header=None)\n",
        "pd.read_csv('ex2.csv', names=['a', 'b', 'c', 'd', 'message'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9dCPJ9kDchAO"
      },
      "source": [
        "Suppose you wanted the message column to be the index of the returned DataFrame.\n",
        "You can either indicate you want the column at index 4 or named 'message' using\n",
        "the index_col argument:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": true,
        "editable": true,
        "id": "kuEgjSqsYfcw"
      },
      "source": [
        "names = ['a', 'b', 'c', 'd', 'message']\n",
        "pd.read_csv('ex2.csv', names=names, index_col='message')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DkAfB5UNdHxK"
      },
      "source": [
        "In some cases, a table might not have a fixed delimiter, using whitespace or some\n",
        "other pattern to separate fields. Consider a text file that looks like this:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": true,
        "editable": true,
        "id": "9Qaasss1YfdA"
      },
      "source": [
        "!cat ex3.txt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2GRmbnjLdX36"
      },
      "source": [
        "While you could do some munging by hand, the fields here are separated by a variable\n",
        "amount of whitespace. In these cases, you can pass a regular expression as a\n",
        "delimiter for read_table. This can be expressed by the regular expression \\s+, so we\n",
        "have then:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": true,
        "editable": true,
        "id": "KnQ9QBwbYfdH"
      },
      "source": [
        "result = pd.read_table('ex3.txt', sep='\\s+')\n",
        "result"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5thrs_LSdeMN"
      },
      "source": [
        "Because there was one fewer column name than the number of data rows,\n",
        "read_table infers that the first column should be the DataFrame’s index in this special\n",
        "case.\n",
        "The parser functions have many additional arguments to help you handle the wide\n",
        "variety of exception file formats that occur (see a partial listing in Table 6-2). For\n",
        "example, you can skip the first, third, and fourth rows of a file with skiprows:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": true,
        "editable": true,
        "id": "-hgrqfCkYfdP"
      },
      "source": [
        "!cat ex4.csv\n",
        "pd.read_csv('ex4.csv', skiprows=[0, 2, 3])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yhZAKTNreT0O"
      },
      "source": [
        "Handling missing values is an important and frequently nuanced part of the file parsing\n",
        "process. Missing data is usually either not present (empty string) or marked by\n",
        "some sentinel value. By default, pandas uses a set of commonly occurring sentinels,\n",
        "such as NA and NULL:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": true,
        "editable": true,
        "id": "83Gjx17IYfdX"
      },
      "source": [
        "!cat ex5.csv\n",
        "result = pd.read_csv('ex5.csv')\n",
        "result\n",
        "pd.isnull(result)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lo9A1Ow7eoeV"
      },
      "source": [
        "The na_values option can take either a list or set of strings to consider missing\n",
        "values:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": true,
        "editable": true,
        "id": "b9RjIad3Yfde"
      },
      "source": [
        "result = pd.read_csv('ex5.csv', na_values=['NULL'])\n",
        "result"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iMgeIcuVetZa"
      },
      "source": [
        "Different NA sentinels can be specified for each column in a dict:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": true,
        "editable": true,
        "id": "lKScVbgzYfdk"
      },
      "source": [
        "sentinels = {'message': ['foo', 'NA'], 'something': ['two']}\n",
        "pd.read_csv('ex5.csv', na_values=sentinels)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": true,
        "editable": true,
        "id": "02oMFSGMYfdr"
      },
      "source": [
        "## Reading Text Files in Pieces"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kp8dTOine5oM"
      },
      "source": [
        "When processing very large files or figuring out the right set of arguments to correctly\n",
        "process a large file, you may only want to read in a small piece of a file or iterate\n",
        "through smaller chunks of the file.\n",
        "Before we look at a large file, we make the pandas display settings more compact:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": true,
        "editable": true,
        "id": "FHREKKaMYfdt"
      },
      "source": [
        "pd.options.display.max_rows = 10"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": true,
        "editable": true,
        "id": "P_Op1_6LYfdx"
      },
      "source": [
        "result = pd.read_csv('ex6.csv')\n",
        "result"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ljqcdGsvfMWG"
      },
      "source": [
        "If you want to only read a small number of rows (avoiding reading the entire file),\n",
        "specify that with nrows:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": true,
        "editable": true,
        "id": "G84inOCEYfd3"
      },
      "source": [
        "pd.read_csv('ex6.csv', nrows=5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TgJiLrWzfPvh"
      },
      "source": [
        "To read a file in pieces, specify a chunksize as a number of rows:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": true,
        "editable": true,
        "id": "Qy3xIhzIYfd9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "2b50e3bd-583f-4a15-9db0-5249af527166"
      },
      "source": [
        "chunker = pd.read_csv('ex6.csv', chunksize=1000)\n",
        "chunker"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<pandas.io.parsers.TextFileReader at 0x7fc58bd1a4e0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-jvekXWAfW79"
      },
      "source": [
        "The TextParser object returned by read_csv allows you to iterate over the parts of\n",
        "the file according to the chunksize. For example, we can iterate over ex6.csv, aggregating\n",
        "the value counts in the 'key' column like so:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": true,
        "editable": true,
        "id": "a76VKZYJYfeD"
      },
      "source": [
        "chunker = pd.read_csv('ex6.csv', chunksize=1000)\n",
        "\n",
        "tot = pd.Series([])\n",
        "for piece in chunker:\n",
        "    tot = tot.add(piece['key'].value_counts(), fill_value=0)\n",
        "\n",
        "tot = tot.sort_values(ascending=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": true,
        "editable": true,
        "id": "c5Qv5VN3YfeL"
      },
      "source": [
        "tot[:10]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": true,
        "editable": true,
        "id": "VjjkOh_0YfeW"
      },
      "source": [
        "## Writing Data to Text Format"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "omgfY_XKf4yr"
      },
      "source": [
        "Data can also be exported to a delimited format. Let’s consider one of the CSV files\n",
        "read before:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": true,
        "editable": true,
        "id": "oV7sqpg6Yfeb"
      },
      "source": [
        "data = pd.read_csv('ex5.csv')\n",
        "data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AsuvLMeBf-gB"
      },
      "source": [
        "Using DataFrame’s to_csv method, we can write the data out to a comma-separated\n",
        "file:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": true,
        "editable": true,
        "id": "Mv85zSYcYfeh"
      },
      "source": [
        "data.to_csv('out.csv')\n",
        "!cat out.csv"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gF1lFGXbgFjY"
      },
      "source": [
        "Other delimiters can be used, of course (writing to sys.stdout so it prints the text\n",
        "result to the console):"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": true,
        "editable": true,
        "id": "ICYjj0eBYfem"
      },
      "source": [
        "import sys\n",
        "data.to_csv(sys.stdout, sep='|')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RkLuzX4SgK3h"
      },
      "source": [
        "Missing values appear as empty strings in the output. You might want to denote them\n",
        "by some other sentinel value:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": true,
        "editable": true,
        "id": "8K_yhZDoYfe3"
      },
      "source": [
        "data.to_csv(sys.stdout, na_rep='NULL')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NyRlbtiCgXza"
      },
      "source": [
        "With no other options specified, both the row and column labels are written. Both of\n",
        "these can be disabled:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": true,
        "editable": true,
        "id": "bPnYWvfrYfe7"
      },
      "source": [
        "data.to_csv(sys.stdout, index=False, header=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uzCgBvGxgbzS"
      },
      "source": [
        "You can also write only a subset of the columns, and in an order of your choosing:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": true,
        "editable": true,
        "id": "kMsyys6IYfe_"
      },
      "source": [
        "data.to_csv(sys.stdout, index=False, columns=['a', 'b', 'c'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wIGslaqKggbX"
      },
      "source": [
        "Series also has a to_csv method:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": true,
        "editable": true,
        "id": "IW5t3ijFYffD"
      },
      "source": [
        "dates = pd.date_range('1/1/2000', periods=7)\n",
        "ts = pd.Series(np.arange(7), index=dates)\n",
        "ts.to_csv('tseries.csv')\n",
        "!cat tseries.csv"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": true,
        "editable": true,
        "id": "Q0vdEaVOYffn"
      },
      "source": [
        "## JSON Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DgJnwg4thhpC"
      },
      "source": [
        "JSON (short for JavaScript Object Notation) has become one of the standard formats\n",
        "for sending data by HTTP request between web browsers and other applications. It is\n",
        "a much more free-form data format than a tabular text form like CSV. Here is an\n",
        "example:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": true,
        "editable": true,
        "id": "Bhvkwn9tYffn"
      },
      "source": [
        "obj = \"\"\"\n",
        "{\"name\": \"Wes\",\n",
        " \"places_lived\": [\"United States\", \"Spain\", \"Germany\"],\n",
        " \"pet\": null,\n",
        " \"siblings\": [{\"name\": \"Scott\", \"age\": 30, \"pets\": [\"Zeus\", \"Zuko\"]},\n",
        "              {\"name\": \"Katie\", \"age\": 38,\n",
        "               \"pets\": [\"Sixes\", \"Stache\", \"Cisco\"]}]\n",
        "}\n",
        "\"\"\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dJUfHDFhhldN"
      },
      "source": [
        "JSON is very nearly valid Python code with the exception of its null value null and\n",
        "some other nuances (such as disallowing trailing commas at the end of lists). The\n",
        "basic types are objects (dicts), arrays (lists), strings, numbers, booleans, and nulls. All\n",
        "of the keys in an object must be strings. There are several Python libraries for reading and writing JSON data. We'll use json here, as it is built into the Python standard\n",
        "library. To convert a JSON string to Python form, use json.loads:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": true,
        "editable": true,
        "id": "1LS18iy1Yffr"
      },
      "source": [
        "import json\n",
        "result = json.loads(obj)\n",
        "result"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wxLzoHAAh6Iz"
      },
      "source": [
        "json.dumps, on the other hand, converts a Python object back to JSON:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": true,
        "editable": true,
        "id": "m3fgrgVtYffz"
      },
      "source": [
        "asjson = json.dumps(result)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b5z5a0GTh8-T"
      },
      "source": [
        "How you convert a JSON object or list of objects to a DataFrame or some other data\n",
        "structure for analysis will be up to you. Conveniently, you can pass a list of dicts\n",
        "(which were previously JSON objects) to the DataFrame constructor and select a subset\n",
        "of the data fields:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": true,
        "editable": true,
        "id": "sO8sL4FDYff2"
      },
      "source": [
        "siblings = pd.DataFrame(result['siblings'], columns=['name', 'age'])\n",
        "siblings"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RLVls6paiACc"
      },
      "source": [
        "The pandas.read_json can automatically convert JSON datasets in specific arrangements\n",
        "into a Series or DataFrame. For example:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": true,
        "editable": true,
        "id": "FeBXdIczYff6"
      },
      "source": [
        "!cat example.json"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9wmrSTA1iHLP"
      },
      "source": [
        "The default options for pandas.read_json assume that each object in the JSON array\n",
        "is a row in the table:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": true,
        "editable": true,
        "id": "tIebvIO3YfgA"
      },
      "source": [
        "data = pd.read_json('example.json')\n",
        "data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": true,
        "editable": true,
        "id": "69_KHhmPYfgJ"
      },
      "source": [
        "##  HTML: Web Scraping"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": true,
        "editable": true,
        "id": "eFcMym8NYfgL"
      },
      "source": [
        "Python has many libraries for reading and writing data in the ubiquitous HTML and\n",
        "XML formats. Examples include lxml, Beautiful Soup, and html5lib. While lxml is\n",
        "comparatively much faster in general, the other libraries can better handle malformed\n",
        "HTML or XML files.\n",
        "\n",
        "Before we scrape a website, we need to take a look at their robots.txt. This file tells us if the website allows scraping or if they do not. To find the robots.txt, type in the base url and add “/robots.txt”. For eg, if we want to crawl shobiddak.com, type in https://www.shobiddak.com/robots.txt at the url box.\n",
        "\n",
        "If the robots.txt allows full access it says as follows:\n",
        "\n",
        "User-agent: *\n",
        "\n",
        "Disallow:\n",
        "\n",
        "If the robots.txt blocks all access, it contains the following:\n",
        "\n",
        "User-agent: *\n",
        "\n",
        "Disallow: /\n",
        "\n",
        "And if the robots.txt gives partial access, it contains the following, where section stands for the sections that are not to be crawled:\n",
        "\n",
        "User-agent: *\n",
        "\n",
        "Disallow: /section/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dT9zAFVyjb5u"
      },
      "source": [
        "Import the necessary libraries:\n",
        "Requests is used in this example to get the html content, BeautifulSoup to parse the html, and pandas to make a dataframe and write to a csv."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": true,
        "editable": true,
        "id": "MwJMO0GaYfgM"
      },
      "source": [
        "import requests \n",
        "from bs4 import BeautifulSoup\n",
        "import pandas\n",
        "import re as reg"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zKbJcj21j2tf"
      },
      "source": [
        "Store the url you want to scrape to a variable. In this example, I go to apartments.com and type in Cincinnati, OH in the search box and press Go as in the screenshot below."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uB8e9T2Ij6Tw"
      },
      "source": [
        "base_url = \"https://shobiddak.com/cars?page=1\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9e-grntTj-_2"
      },
      "source": [
        "Get the html contents from the page. This is done using the requests library"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PIoFBjeDkA7j"
      },
      "source": [
        "r = requests.get(base_url)\n",
        "c = r.content"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aVK_dn6ykEP0"
      },
      "source": [
        "Parse the html. This is done with BeautifulSoup."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0mG9mMQzkFCB"
      },
      "source": [
        "soup = BeautifulSoup(c,\"html.parser\")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QSfDNUCRkOHk"
      },
      "source": [
        " Extract the first and last page numbers. We need to be able to find the first and the last page numbers in order to be able to crawl through all of the pages on the website dynamically. To do this click on the paging section at the end of the page as shown in the screen shot below and right click to inspect."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2GdDwbJ1kaHo"
      },
      "source": [
        "# To extract the first and last page numbers\n",
        "paging = soup.find(\"div\",{\"class\":\"all_contents\"}).find(\"div\",{\"class\":\"pagination\"}).find_all(\"a\") \n",
        "#or if you want to use css selector         paging = soup.select('.pagination a')\n",
        "start_page = paging[1].text\n",
        "last_page = paging[len(paging)-2].text"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OXFenejppgbF"
      },
      "source": [
        "Make page links from the page numbers ,crawl through the pages and extract the contents from the corresponding tags. We start a for loop to iterate through each of the pages."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hipUlAlRphUl"
      },
      "source": [
        "base_url=\"https://shobiddak.com/cars?page=\"\n",
        "for page_number in range(int(start_page),3):\n",
        "    \n",
        "    # To form the url based on page numbers\n",
        "    url = base_url+str(page_number)\n",
        "    print(url)\n",
        "    r = requests.get(base_url+str(page_number)+\"/\")\n",
        "    c = r.content\n",
        "    \n",
        "    #soup = BeautifulSoup(c,\"html.parser\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kjNKV-1Gzw0b"
      },
      "source": [
        "Extract the header class for title and year.Right click on the title and inspect."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iCpAPK1tz7J2"
      },
      "source": [
        "# To extract the Title,year,color and price\n",
        "    placard_header = soup.find_all(\"div\", {\"class\":\"col-xs-4 fixed-box-height guide-card\"})\n",
        "    print(placard_header[0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bQh_OzbL0KSV"
      },
      "source": [
        "Start a for loop to process car by car and extract the values of Car, Color, Year. We extract the individual values by accessing into the inner most tag with the value. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MIE9i3y50Lmd"
      },
      "source": [
        "# To process property by property by looping\n",
        "    web_content_list=[]\n",
        "    for item_header in placard_header:\n",
        "      \n",
        "      # To store the information to a dictionary\n",
        "      web_content_dict = {}    \n",
        "      \n",
        "      year_color = item_header.find(\"p\",{\"class\":\"second-info\"}).find_all(\"a\")\n",
        "      web_content_dict[\"Year\"] = year_color[0].text\n",
        "      web_content_dict[\"Color\"] = year_color[1].text      \n",
        "      web_content_dict[\"Car\"]=item_header.find(\"p\",{\"class\":\"section_title\"}).text\n",
        "      # To store the dictionary to into a list\n",
        "      web_content_list.append(web_content_dict)\n",
        "\n",
        "\n",
        "      # Or you can use the stripped_strings method  \n",
        "      '''\n",
        "      for div in ads:\n",
        "              L = []\n",
        "              for p in div.stripped_strings:            \n",
        "                L.append(reg.sub('-\\s+','',p,count=0))\n",
        "                print(p)\n",
        "              web_content_list.append(L)   \n",
        "                '''\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hwNuYbi70Oxu"
      },
      "source": [
        "Make a dataframe with the list and write the list to a csv file"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QTYaMqYq0QtL"
      },
      "source": [
        "df = pd.DataFrame(web_content_list,columns=['Model','Year of Man','hyphen','Color','Price','City','Date of ad'])\n",
        "\n",
        "\n",
        "\n",
        "# To write the dataframe to a csv file\n",
        "df.to_csv(\"Output.csv\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": true,
        "editable": true,
        "id": "9rFy55xmYfhc"
      },
      "source": [
        "## Interacting with Web APIs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vAGtx5FHJ5eq"
      },
      "source": [
        "Many websites have public APIs providing data feeds via JSON or some other format.\n",
        "There are a number of ways to access these APIs from Python; one easy-to-use\n",
        "method that I recommend is the requests package.\n",
        "To find the last 30 GitHub issues for pandas on GitHub, we can make a GET HTTP\n",
        "request using the add-on requests library:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": true,
        "editable": true,
        "id": "ReuOuTqKYfhc"
      },
      "source": [
        "import requests\n",
        "url = 'https://api.github.com/repos/pandas-dev/pandas/issues'\n",
        "resp = requests.get(url)\n",
        "resp"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O48SYq4WJ9F2"
      },
      "source": [
        "The Response object’s json method will return a dictionary containing JSON parsed\n",
        "into native Python objects:\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": true,
        "editable": true,
        "id": "s-1YheKiYfhf"
      },
      "source": [
        "data = resp.json()\n",
        "print(data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NTB_khBdKOgC"
      },
      "source": [
        "Each element in data is a dictionary containing all of the data found on a GitHub\n",
        "issue page (except for the comments). We can pass data directly to DataFrame and\n",
        "extract fields of interest:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": true,
        "editable": true,
        "id": "Mt2lCuncYfhi"
      },
      "source": [
        "issues = pd.DataFrame(data)\n",
        "issues\n",
        "\n",
        "print(issues.loc[0,'url']) #print the first row in url column\n",
        "print(issues.loc[0,'html_url'])#print the first row in html_url column\n",
        "print(issues.user[0]['login']) # print the value of login key from the first row if the user column"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": true,
        "editable": true,
        "id": "kjxx8TbFYfhl"
      },
      "source": [
        "## Interacting with Databases"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": true,
        "editable": true,
        "id": "DudCLjQKYfhm"
      },
      "source": [
        "## you can use the DB engine library or SQLalchemy which is an Object Relational Mapper  \n",
        "\n",
        "import sqlite3\n",
        "query = \"\"\"\n",
        "CREATE TABLE test\n",
        "(a VARCHAR(20), b VARCHAR(20),\n",
        " c REAL,        d INTEGER\n",
        ");\"\"\"\n",
        "con = sqlite3.connect('mydata.sqlite')\n",
        "con.execute(query)\n",
        "con.commit()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": true,
        "editable": true,
        "id": "iwGkGJcxYfhp"
      },
      "source": [
        "data = [('Atlanta', 'Georgia', 1.25, 6),\n",
        "        ('Tallahassee', 'Florida', 2.6, 3),\n",
        "        ('Sacramento', 'California', 1.7, 5)]\n",
        "stmt = \"INSERT INTO test VALUES(?, ?, ?, ?)\"\n",
        "con.executemany(stmt, data)\n",
        "con.commit()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": true,
        "editable": true,
        "id": "cRjFEMv7Yfht"
      },
      "source": [
        "cursor = con.execute('select * from test')\n",
        "rows = cursor.fetchall()\n",
        "rows"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": true,
        "editable": true,
        "id": "SjghT_5AYfhv"
      },
      "source": [
        "cursor.description\n",
        "pd.DataFrame(rows, columns=[x[0] for x in cursor.description])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1zOixsjCZ3Qp"
      },
      "source": [
        "Using SQLalchemy to store the data from web scaping to a sqlite DB"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": true,
        "editable": true,
        "id": "lBfOKP3aYfh-"
      },
      "source": [
        "from flask_sqlalchemy import  SQLAlchemy\n",
        "from flask import Flask"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": true,
        "editable": true,
        "id": "NYy6sqDzYfiA"
      },
      "source": [
        "app= Flask(__name__)\r\n",
        "app.config['SQLALCHEMY_DATABASE_URI']= 'sqlite:///site.db'\r\n",
        "\r\n",
        "db=SQLAlchemy(app)\r\n",
        "\r\n",
        "class Car(db.Model):\r\n",
        "    id = db.Column(db.Integer,primary_key=True)   \r\n",
        "    model = db.Column(db.String(128),nullable=True) \r\n",
        "    year_man = db.Column(db.Integer,nullable=False)\r\n",
        "    def __repr__(self):\r\n",
        "        return f\"Car('{self.model}',{self.year_man}')\"\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "car1 = Car(model=df['Model'][0],year_man =df.loc[0,'Year of Man'])\r\n",
        "db.session.add(car1)\r\n",
        "db.session.commit()\r\n",
        "print(Car.query.all())"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}